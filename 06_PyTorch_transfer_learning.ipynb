{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNNGJFDrwNOLEqy1yCmdOcn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradGonrad/PyTorch-deep-learning/blob/main/06_PyTorch_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQQH-HXqt-CU"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import torch\n",
        "  import torchvision\n",
        "  assert (int(torch.__version__.split('.')[0]) > 1) or \\\n",
        "          (int(torch.__version__.split('.')[0]) == 1 and int(torch.__version__.split('.')[1]) >= 12), 'torch must have newer version than 1.12'\n",
        "  assert (int(torchvision.__version__.split('.')[1]) >= 13), 'torchvision must be newer version than 0.13'\n",
        "except:\n",
        "  print(f'[INFO] torch/torchvision version not as required. Installing newer version')\n",
        "  !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  import torch\n",
        "  import torchvision\n",
        "  print(f'torch version: {torch.__version__}')\n",
        "  print(f'torchvision version: {torchvision.__version__}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path('data/')\n",
        "IMAGE_PATH = DATA_PATH / 'pizza_steak_sushi'\n",
        "\n",
        "if IMAGE_PATH.is_dir():\n",
        "  print(f\"{IMAGE_PATH} directory already exists\")\n",
        "else:\n",
        "  print(f\"Did not find {IMAGE_PATH} directory, creating one...\")\n",
        "  IMAGE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  with open(DATA_PATH / 'pizza_steak_sushi.zip', 'wb') as f:\n",
        "    request = requests.get('https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip')\n",
        "    f.write(request.content)\n",
        "\n",
        "  with zipfile.ZipFile(DATA_PATH / 'pizza_steak_sushi.zip', 'r') as zipf:\n",
        "    zipf.extractall(IMAGE_PATH)\n",
        "\n",
        "  os.remove(DATA_PATH / 'pizza_steak_sushi.zip')\n"
      ],
      "metadata": {
        "id": "GdC9cZw9uBEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = IMAGE_PATH / 'train'\n",
        "TEST_DIR = IMAGE_PATH / 'test'"
      ],
      "metadata": {
        "id": "FeR6VAr8uBaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Additional_func_path = Path('add/')\n",
        "\n",
        "if Additional_func_path.is_dir():\n",
        "  print(f'{Additional_func_path} already exists.')\n",
        "else:\n",
        "  print(f\"Can't find {Additional_func_path}. Creating one..\")\n",
        "  Additional_func_path.mkdir(parents=True, exist_ok = True)\n",
        "  with open(Additional_func_path / 'notebook_5.ipynb', 'wb') as f:\n",
        "    request = requests.get('https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/Kopia_notatnika_05_pytorch_going_modular_exercise_template.ipynb')\n",
        "\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "jRlU6OlSNYA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ADD_FUNS_PATH = Path('Additional_functions/')\n",
        "\n",
        "if ADD_FUNS_PATH.is_dir():\n",
        "  print(f'{ADD_FUNS_PATH} path is already created')\n",
        "else:\n",
        "  print(f'Creating {ADD_FUNS_PATH} path')\n",
        "  ADD_FUNS_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  urls = ['https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/additional_functions/data_setup.py',\n",
        "          'https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/additional_functions/engine.py',\n",
        "          'https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/additional_functions/get_data.py',\n",
        "          'https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/additional_functions/model_builder.py',\n",
        "          'https://github.com/KonradGonrad/PyTorch-deep-learning/raw/main/additional_functions/utils.py']\n",
        "\n",
        "  for url in urls:\n",
        "    local_filename = url.split('/')[-1]\n",
        "    request = requests.get(url)\n",
        "    with open(ADD_FUNS_PATH / local_filename, 'wb') as f:\n",
        "      f.write(request.content)"
      ],
      "metadata": {
        "id": "6Tk4UPVwT-CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append(str(ADD_FUNS_PATH))\n",
        "sys.path"
      ],
      "metadata": {
        "id": "DqX_j18lB6y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model_builder import TinyVGG\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model_1 =TinyVGG(input_channels = 3,\n",
        "                 hidden_channels = 10,\n",
        "                 output_channels = 3)\n",
        "\n",
        "dummy = torch.randn(size=(1, 3, 64, 64))\n",
        "torch.argmax(torch.softmax(model_1(dummy), dim=1), dim=1)"
      ],
      "metadata": {
        "id": "P0mb8FafC5oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "torch.manual_seed(42)\n",
        "\n",
        "manual_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "-AtDPKxaDDQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from data_setup import prepare_data\n",
        "\n",
        "prepared_data = prepare_data(transforms=manual_transform,\n",
        "                             train_dir = TRAIN_DIR,\n",
        "                             test_dir = TEST_DIR,\n",
        "                             batch_size = 1)\n",
        "\n",
        "train_dataloader, test_dataloader = prepared_data['train_dataloader'], prepared_data['test_dataloader']\n",
        "class_names = prepared_data['class_names']"
      ],
      "metadata": {
        "id": "8WkJBWhRi2ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "weights"
      ],
      "metadata": {
        "id": "nE7fcp01jw8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_transforms = weights.transforms()\n",
        "auto_transforms"
      ],
      "metadata": {
        "id": "dArpG-vZkhZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_data = prepare_data(transforms=auto_transforms,\n",
        "                             train_dir = TRAIN_DIR,\n",
        "                             test_dir = TEST_DIR,\n",
        "                             batch_size=32)\n",
        "\n",
        "train_dataloader = prepared_data['train_dataloader']\n",
        "test_dataloader = prepared_data['test_dataloader']\n",
        "class_names = prepared_data['class_names']\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "id": "1IcuMybIktUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to('cpu')"
      ],
      "metadata": {
        "id": "rNcG6RoFlLfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224),\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        col_width = 20,\n",
        "        row_settings = ['var_names']\n",
        "        )"
      ],
      "metadata": {
        "id": "oAEqz5hjrKcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.features.parameters():\n",
        "  param.requires_grad = False"
      ],
      "metadata": {
        "id": "9EPRBmYOrxuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "output_shape = len(class_names)\n",
        "\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p = 0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features = output_shape,\n",
        "                    bias=True)\n",
        ").to('cpu')"
      ],
      "metadata": {
        "id": "yMnScGhGxXvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model=model,\n",
        "        input_size=(32, 3, 224, 224),\n",
        "        verbose=0,\n",
        "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
        "        col_width = 20,\n",
        "        row_settings=['var_names'])"
      ],
      "metadata": {
        "id": "yvN1aPqYyDdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "GLa9h5WByass"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from engine import train\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "results = train(model=model,\n",
        "                test_dataloader = test_dataloader,\n",
        "                train_dataloader = train_dataloader,\n",
        "                optimizer = optimizer,\n",
        "                loss_fn = loss_fn,\n",
        "                epochs = 6,\n",
        "                device = 'cpu')\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"[INFO] total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "VF6RAlQAveNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "id": "W4dNjtWNAnlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curves(results):\n",
        "  train_loss, test_loss = results['train_loss'], results['test_loss']\n",
        "  train_acc, test_acc = results['train_acc'], results['test_acc']\n",
        "\n",
        "  epochs = range(len(results['train_loss']))\n",
        "\n",
        "  plt.figure(figsize=(15, 7))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs, train_loss, label='train_loss')\n",
        "  plt.plot(epochs, test_loss, label='test_loss')\n",
        "  plt.title('Loss (lower = better)')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs, train_acc, label='train_accuracy')\n",
        "  plt.plot(epochs, test_acc, label='test_accuracy')\n",
        "  plt.title('Accuracy (higher = better)')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "Ys6WZ7APwUTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(results)"
      ],
      "metadata": {
        "id": "q1CTYOIY_Vw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str],\n",
        "                        device: torch.device,\n",
        "                        image_size: Tuple[int, int] = [224, 224],\n",
        "                        transform: torchvision.transforms = None\n",
        "                        ):\n",
        "  image = Image.open(fp=image_path)\n",
        "\n",
        "  if transform is not None:\n",
        "    image_transform = transform\n",
        "  else:\n",
        "    image_transform = transforms.Compose([\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "  model.to(device)\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    transformed_image = image_transform(image).unsqueeze(dim=0)\n",
        "    image_pred = model(transformed_image.to(device))\n",
        "\n",
        "    image_pred_prob = torch.softmax(image_pred, dim=1)\n",
        "    image_pred_label = torch.argmax(image_pred_prob, dim=1)\n",
        "\n",
        "  plt.figure()\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  if class_names is None:\n",
        "    title = f'It\\'s {image_pred_label}'\n",
        "  else:\n",
        "    title = f'It\\'s {class_names[image_pred_label]} | Probability: {image_pred_prob.max():.2f}'\n",
        "  plt.title(title);"
      ],
      "metadata": {
        "id": "hg6S1SO6BYW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "num_images_to_plot = 3\n",
        "test_image_path_list = list(Path(TEST_DIR).glob('*/*.jpg'))\n",
        "random_image = random.sample(population=test_image_path_list,\n",
        "                             k=num_images_to_plot)\n",
        "\n",
        "for image_path in test_image_path_list:\n",
        "  pred_and_plot_image(model=model,\n",
        "                      image_path = image_path,\n",
        "                      class_names=class_names,\n",
        "                      device='cpu',\n",
        "                      transform=weights.transforms(),\n",
        "                      image_size=(224, 224))"
      ],
      "metadata": {
        "id": "cPB-DMwuNco5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RjtieHr1Qi4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}