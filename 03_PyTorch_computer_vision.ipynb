{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPO0MclgBuPn0+39HtCPD5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradGonrad/PyTorch-deep-learning/blob/main/03_PyTorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision"
      ],
      "metadata": {
        "id": "fjW3yUa9ZTKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Computer vision libaries in PyTorch\n",
        "\n",
        "* [`torchvision`](https://pytorch.org/vision/stable/index.html) - base domain libary for Pytorch computer vision\n",
        "* `torchvision.datasets` - databases and data loading functions for computer vision\n",
        "* `torchvision.models` - get pretrained computer vision models that can leverage your own problems\n",
        "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with and ML model\n",
        "* `torch.utils.data.Dataset` - Base dataset class for PyTorch\n",
        "* `torch.utils.data.Dataloader` - Creates a Python iterable over a dataset\n"
      ],
      "metadata": {
        "id": "skncr061a7zC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZUiydpoLOIT"
      },
      "outputs": [],
      "source": [
        "# Impoprt PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import pandas (maybe will be needed)\n",
        "import pandas as pd\n",
        "\n",
        "# Check version\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a dataset\n",
        "\n",
        "FashionMNIST is a dataset of greyscale images of clothingf"
      ],
      "metadata": {
        "id": "1PCWbJWndQWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "VpWu9EvtgzaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of training data: {len(train_data)}\")\n",
        "print(f\"length of testing data: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "7JsaTSDEhY3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = train_data[0]\n",
        "print(data.shape, label)"
      ],
      "metadata": {
        "id": "wMC2gpixhxnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_classes = train_data.classes\n",
        "target_classes"
      ],
      "metadata": {
        "id": "BvO6J51Fh61Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_to_idx = train_data.class_to_idx\n",
        "classes_to_idx"
      ],
      "metadata": {
        "id": "3xxFYZuFiHeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "WsmX4iLysYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Check Input and output shapes of data"
      ],
      "metadata": {
        "id": "XQESHMymseXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data of shape {data.shape} -> [Color, Height, Weight] equals {target_classes[label]}\")"
      ],
      "metadata": {
        "id": "ag4qJ5kriLRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualizing our data\n"
      ],
      "metadata": {
        "id": "oRULfsAus5Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting up a random seed to have same outputs\n",
        "fig = plt.figure(figsize=(9, 9)) # Creating a figure, where we'll put our subplots\n",
        "rows, cols = [4, 4] # Setting up dimension, there is 4x4 what gives us 16 pics\n",
        "for i in range(1, rows*cols + 1): # Setting up loop to put our imgs into figure\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item() # Getting random index from 0 to train_data max index\n",
        "  img, label = train_data[random_idx] # assign img and label to variables\n",
        "  fig.add_subplot(rows, cols, i) # Adding subplot to figure at i index\n",
        "  plt.imshow(img.squeeze(), cmap='gray') # Creating image plot which is added to figure\n",
        "  plt.title(target_classes[label]) # Adding title\n",
        "  plt.axis(False) # Removing aaxis, beacouse it's useless in our case"
      ],
      "metadata": {
        "id": "1kF2GmvLs86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think these items of clothing (images) could be modelled with pure linear lines? Or do you think we'll need non-linearities"
      ],
      "metadata": {
        "id": "JQ8uN-9mu84U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare dataloader\n",
        "\n",
        "Right now, our data is in the form of PyTorch datasets\n",
        "\n",
        "DataLoader turns our dataset into Python iterable\n",
        "\n",
        "More specifically, we want to turn our data into batches (or mini-batches).\n",
        "\n",
        "Why would we do this?\n",
        "\n",
        "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32)\n",
        "2. It gives our neural network more chances to update its gradients per epoch\n",
        "\n",
        "for more on [mini-batches](https://www.bilibili.com/video/BV1RE411Z7YW/)"
      ],
      "metadata": {
        "id": "K7SJUJdexYHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "mxMSfWcQxekk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "uKJabur4xfmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
      ],
      "metadata": {
        "id": "cIXFMoXneuka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "print(f\"train_feature_batch shape: {train_features_batch.shape} and train_labels_batch shape: {train_labels_batch.shape}\")"
      ],
      "metadata": {
        "id": "QlxmSGXjgWMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, title = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.title(target_classes[label])\n",
        "plt.axis(False)\n",
        "print(f\"image shape: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {title.shape}\")"
      ],
      "metadata": {
        "id": "6fWfSPSDg4QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Model 0: Build a baseline model"
      ],
      "metadata": {
        "id": "G0_HPN_Rrjcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "flatten_layer = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "x\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_layer(x)\n",
        "output"
      ],
      "metadata": {
        "id": "RubRCpU107Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_features: int,\n",
        "               hidden_layers: int,\n",
        "               output_features: int):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_features, out_features=hidden_layers),\n",
        "        nn.Linear(in_features=hidden_layers, out_features=output_features)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_1(x)\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "x5wRwMkw1Fn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = FashionMNISTModelV0(input_features=28*28,\n",
        "                              hidden_layers=10,\n",
        "                              output_features=len(target_classes))"
      ],
      "metadata": {
        "id": "g4sYMaff1Dj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(x).shape"
      ],
      "metadata": {
        "id": "N-qfRksn4Hfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dummy = torch.rand([1, 1, 28, 28])\n",
        "model_0(x_dummy).shape"
      ],
      "metadata": {
        "id": "mtbMldj74iw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aD7suvhZERV3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}