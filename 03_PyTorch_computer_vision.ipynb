{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXmG0c96rI5nKBvZaavOQN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradGonrad/PyTorch-deep-learning/blob/main/03_PyTorch_computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Computer Vision"
      ],
      "metadata": {
        "id": "fjW3yUa9ZTKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Computer vision libaries in PyTorch\n",
        "\n",
        "* [`torchvision`](https://pytorch.org/vision/stable/index.html) - base domain libary for Pytorch computer vision\n",
        "* `torchvision.datasets` - databases and data loading functions for computer vision\n",
        "* `torchvision.models` - get pretrained computer vision models that can leverage your own problems\n",
        "* `torchvision.transforms` - functions for manipulating your vision data (images) to be suitable for use with and ML model\n",
        "* `torch.utils.data.Dataset` - Base dataset class for PyTorch\n",
        "* `torch.utils.data.Dataloader` - Creates a Python iterable over a dataset\n"
      ],
      "metadata": {
        "id": "skncr061a7zC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZUiydpoLOIT"
      },
      "outputs": [],
      "source": [
        "# Impoprt PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "# Import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import pandas (maybe will be needed)\n",
        "import pandas as pd\n",
        "\n",
        "# Check version\n",
        "print(torch.__version__)\n",
        "print(torchvision.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Getting a dataset\n",
        "\n",
        "FashionMNIST is a dataset of greyscale images of clothingf"
      ],
      "metadata": {
        "id": "1PCWbJWndQWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    target_transform=None\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        "    target_transform=None\n",
        ")"
      ],
      "metadata": {
        "id": "VpWu9EvtgzaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"length of training data: {len(train_data)}\")\n",
        "print(f\"length of testing data: {len(test_data)}\")"
      ],
      "metadata": {
        "id": "7JsaTSDEhY3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = train_data[0]\n",
        "print(data.shape, label)"
      ],
      "metadata": {
        "id": "wMC2gpixhxnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_classes = train_data.classes\n",
        "target_classes"
      ],
      "metadata": {
        "id": "BvO6J51Fh61Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_to_idx = train_data.class_to_idx\n",
        "classes_to_idx"
      ],
      "metadata": {
        "id": "3xxFYZuFiHeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "id": "WsmX4iLysYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Check Input and output shapes of data"
      ],
      "metadata": {
        "id": "XQESHMymseXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"data of shape {data.shape} -> [Color, Height, Weight] equals {target_classes[label]}\")"
      ],
      "metadata": {
        "id": "ag4qJ5kriLRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2 Visualizing our data\n"
      ],
      "metadata": {
        "id": "oRULfsAus5Z1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42) # Setting up a random seed to have same outputs\n",
        "fig = plt.figure(figsize=(9, 9)) # Creating a figure, where we'll put our subplots\n",
        "rows, cols = [4, 4] # Setting up dimension, there is 4x4 what gives us 16 pics\n",
        "for i in range(1, rows*cols + 1): # Setting up loop to put our imgs into figure\n",
        "  random_idx = torch.randint(0, len(train_data), size=[1]).item() # Getting random index from 0 to train_data max index\n",
        "  img, label = train_data[random_idx] # assign img and label to variables\n",
        "  fig.add_subplot(rows, cols, i) # Adding subplot to figure at i index\n",
        "  plt.imshow(img.squeeze(), cmap='gray') # Creating image plot which is added to figure\n",
        "  plt.title(target_classes[label]) # Adding title\n",
        "  plt.axis(False) # Removing aaxis, beacouse it's useless in our case"
      ],
      "metadata": {
        "id": "1kF2GmvLs86J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you think these items of clothing (images) could be modelled with pure linear lines? Or do you think we'll need non-linearities"
      ],
      "metadata": {
        "id": "JQ8uN-9mu84U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Prepare dataloader\n",
        "\n",
        "Right now, our data is in the form of PyTorch datasets\n",
        "\n",
        "DataLoader turns our dataset into Python iterable\n",
        "\n",
        "More specifically, we want to turn our data into batches (or mini-batches).\n",
        "\n",
        "Why would we do this?\n",
        "\n",
        "1. It is more computationally efficient, as in, your computing hardware may not be able to look (store in memory) at 60000 images in one hit. So we break it down to 32 images at a time (batch size of 32)\n",
        "2. It gives our neural network more chances to update its gradients per epoch\n",
        "\n",
        "for more on [mini-batches](https://www.bilibili.com/video/BV1RE411Z7YW/)"
      ],
      "metadata": {
        "id": "K7SJUJdexYHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data"
      ],
      "metadata": {
        "id": "mxMSfWcQxekk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "uKJabur4xfmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}...\")\n",
        "print(f\"test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}...\")"
      ],
      "metadata": {
        "id": "cIXFMoXneuka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
        "print(f\"train_feature_batch shape: {train_features_batch.shape} and train_labels_batch shape: {train_labels_batch.shape}\")"
      ],
      "metadata": {
        "id": "QlxmSGXjgWMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
        "img, title = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
        "plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.title(target_classes[label])\n",
        "plt.axis(False)\n",
        "print(f\"image shape: {img.shape}\")\n",
        "print(f\"Label: {label}, label size: {title.shape}\")"
      ],
      "metadata": {
        "id": "6fWfSPSDg4QR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Model 0: Build a baseline model"
      ],
      "metadata": {
        "id": "G0_HPN_Rrjcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a flatten layer\n",
        "flatten_layer = nn.Flatten()\n",
        "\n",
        "# Get a single sample\n",
        "x = train_features_batch[0]\n",
        "x\n",
        "\n",
        "# Flatten the sample\n",
        "output = flatten_layer(x)\n",
        "output"
      ],
      "metadata": {
        "id": "RubRCpU107Nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "class FashionMNISTModelV0(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_features: int,\n",
        "               hidden_layers: int,\n",
        "               output_features: int):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_features, out_features=hidden_layers),\n",
        "        nn.Linear(in_features=hidden_layers, out_features=output_features)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_1(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "x5wRwMkw1Fn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = FashionMNISTModelV0(input_features=784,\n",
        "                              hidden_layers=10,\n",
        "                              output_features=len(target_classes))"
      ],
      "metadata": {
        "id": "g4sYMaff1Dj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0(x).shape"
      ],
      "metadata": {
        "id": "N-qfRksn4Hfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_dummy = torch.rand([1, 1, 28, 28])\n",
        "model_0(x_dummy).shape"
      ],
      "metadata": {
        "id": "mtbMldj74iw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "aD7suvhZERV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Setup loss function, optimizer and evaluation metrics\n",
        "\n",
        "* Loss Function - since we're working with multi-class data, our loss function will be 'nn.CrossEntropyLoss()'\n",
        "* Optimizer - our optimizer 'torch.optim.SGD()' (stochastic gradient descent)\n",
        "* Evaluation metric - since we're working on a classification problem, let's use accuracy as our evaluation metric\n",
        "\n"
      ],
      "metadata": {
        "id": "CObjsdpiPunc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import requests\n",
        "\n",
        "if Path('helper_functions.py').is_file():\n",
        "  print('helper_functions.py is already downloaded')\n",
        "else:\n",
        "  print(\"Downloading helper_functions.py\")\n",
        "  request = requests.get('https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py')\n",
        "  with open('helper_functions.py', 'wb') as f:\n",
        "    f.write(request.content)"
      ],
      "metadata": {
        "id": "MPdqNWcBTyRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import accuracy_fn\n",
        "from helper_functions import accuracy_fn\n",
        "\n",
        "# Loss fn and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_0.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "_VrogSxPUUpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Creating a function to time our experiments\n",
        "\n",
        "Machine learning is very experimental.\n",
        "\n",
        "Two of the main thing you'll often want to track are:\n",
        "1. Model's performance(loss and accuracy values etc)\n",
        "2. How fast it runs"
      ],
      "metadata": {
        "id": "CEoceU2xVOQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "def time_start_end(start_time: float,\n",
        "                   end_time: float,\n",
        "                   device: torch.device = None):\n",
        "  total_time = end_time - start_time\n",
        "  print(f\"Took about {total_time:.3f} seconds to execute the code on {device}\")\n",
        "  return total_time"
      ],
      "metadata": {
        "id": "ZISN4dKVZMEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = timer()\n",
        "# break\n",
        "end = timer()\n",
        "\n",
        "time_start_end(start_time=start,\n",
        "               end_time=end,\n",
        "               device='cpu')"
      ],
      "metadata": {
        "id": "lnSurxTYZ2w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3 Creating a training loop and training a model on batches of data\n",
        "\n",
        "1. Loop through epochs.\n",
        "2. Loop through training batches, perform training steps, calculate the train loss *per batch*\n",
        "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*.\n",
        "4. Print out what's happening.\n",
        "5. Time it all"
      ],
      "metadata": {
        "id": "aBGzve8KaJVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import tqdm for progress bar\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Set the seed and start the timer\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "train_loop_start_time = timer()\n",
        "\n",
        "# Set the number of epochs(we'll keep this small for faster training time)\n",
        "epochs = 3\n",
        "\n",
        "# Create training and test loop\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f\"Epoch: {epoch}\\n-----\")\n",
        "  #Training\n",
        "  train_loss, train_acc = 0, 0\n",
        "  # Add a loop to loop thorught the training batches\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model_0.train()\n",
        "    # 1. Forward pass\n",
        "    y_pred = model_0(X)\n",
        "\n",
        "    # 2. Calculate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    acc = accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
        "    train_acc += acc\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4.Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print out what's happening\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Progress: {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  # divide total train loss by length of train dataloader\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  ### Testing\n",
        "  test_loss, test_acc = 0, 0\n",
        "  model_0.eval()\n",
        "  with torch.inference_mode():\n",
        "\n",
        "    for X, y in test_dataloader:\n",
        "      # 1. Forward pas\n",
        "      test_pred = model_0(X)\n",
        "\n",
        "      # 2. Calculate the loss\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "\n",
        "      # 3. Calculate accuracy\n",
        "      test_acc += accuracy_fn(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    # Calculate the test loss average per batch\n",
        "    test_loss /= len(test_dataloader)\n",
        "\n",
        "    # Calculate the test acc average per batch\n",
        "    test_acc /= len(test_dataloader)\n",
        "\n",
        "  # Print out what's happening\n",
        "  print(f\"Train_loss: {train_loss:.5f}, Train_acc: {train_acc:.5f} | Test_loss: {test_loss:.5f}, Test_acc: {test_acc:.5f}\")\n",
        "\n",
        "# Calculate training time\n",
        "train_loop_end_time = timer()\n",
        "total_train_time_model_0 = time_start_end(start_time=train_loop_start_time,\n",
        "               end_time=train_loop_end_time,\n",
        "               device=str(next(model_0.parameters()).device))\n"
      ],
      "metadata": {
        "id": "oHbouyZmbhr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_0.parameters()).device"
      ],
      "metadata": {
        "id": "KWvN2RkpnhmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Make predictions and get model 0 results"
      ],
      "metadata": {
        "id": "r8cOEX7fFEMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "def eval_mode(data: torch.utils.data.DataLoader,\n",
        "              model: torch.nn.Module,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              acc_fn,\n",
        "              device: torch.device\n",
        "              ):\n",
        "  loss, acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for X, y in tqdm(data):\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      y_pred = model(X)\n",
        "\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += acc_fn(y, y_pred.argmax(dim=1))\n",
        "    loss /= len(data)\n",
        "    acc /= len(data)\n",
        "  return {\"model\": model.__class__.__name__,\n",
        "          \"loss\": round(loss.item(), 2),\n",
        "          \"acc\": round(acc, 2)}"
      ],
      "metadata": {
        "id": "BUU_qZvdFR8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results = eval_mode(data=test_dataloader,\n",
        "          model = model_0,\n",
        "          loss_fn=loss_fn,\n",
        "          acc_fn=accuracy_fn,\n",
        "          device='cpu')"
      ],
      "metadata": {
        "id": "2V-mjKN-FRvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Setup device agnostic-code (for using a gpu if there is one)\n"
      ],
      "metadata": {
        "id": "f6Tu3ehmdXOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device agnostic code\n",
        "DEVICE_DESTINATION = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE_DESTINATION"
      ],
      "metadata": {
        "id": "yRb942yDoHc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "  !nvidia-smi\n",
        "else:\n",
        "  print('no gpu found')"
      ],
      "metadata": {
        "id": "qr5DvJjhoPAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Building a better model with non-linearity\n",
        "\n",
        "We learned about the power of non-linearity"
      ],
      "metadata": {
        "id": "THxU7Yie16cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FashionMNISTModelV1(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_layers: int,\n",
        "               hidden_layers: int,\n",
        "               output_layers: int):\n",
        "    super().__init__()\n",
        "    self.layer_1 = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=input_layers, out_features=hidden_layers),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(in_features=hidden_layers, out_features=output_layers ),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.layer_1(x)"
      ],
      "metadata": {
        "id": "7ClJqINgpMy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = FashionMNISTModelV1(input_layers=784,\n",
        "                              hidden_layers=10,\n",
        "                              output_layers=len(target_classes)).to(DEVICE_DESTINATION)\n",
        "model_1"
      ],
      "metadata": {
        "id": "3S8fuqIZ02EN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(model_1.parameters()).device"
      ],
      "metadata": {
        "id": "vmaor1ZS08Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Setup loss and evaluation metrics"
      ],
      "metadata": {
        "id": "YQHU5V-l6zL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(params=model_1.parameters(),\n",
        "                            lr=0.1)"
      ],
      "metadata": {
        "id": "Qx3WjzUc1zX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2 Functionizing training and evaluation/testing loops\n",
        "Let's create a function for:\n",
        "* training loop - train_step()\n",
        "* testing loop - test_step"
      ],
      "metadata": {
        "id": "ljmenr_e63-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model: torch.nn.Module,\n",
        "               data: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn,\n",
        "               acc_fn: any,\n",
        "               optimizer: torch.optim,\n",
        "               device: torch.device = DEVICE_DESTINATION):\n",
        "  \"\"\"Performs a training loop step on model going over data_loader\"\"\"\n",
        "  train_loss, train_acc = 0, 0\n",
        "  model.train()\n",
        "  for batch, (X, y) in enumerate(data):\n",
        "    # 0. Data on target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    # 1. forward pass\n",
        "    y_pred = model(X) # Logits\n",
        "\n",
        "    # 2. Calculate the loss and accuracy\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    acc = acc_fn(y, y_pred.argmax(dim=1))\n",
        "\n",
        "    train_loss += loss\n",
        "    train_acc += acc\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backwards\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimzizer step step step\n",
        "    optimizer.step()\n",
        "  train_loss /= len(data)\n",
        "  train_acc /= len(data)\n",
        "\n",
        "  print(f\"Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f}%\\n\")"
      ],
      "metadata": {
        "id": "oHAXE2Cb4Qvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_step(model: torch.nn.Module,\n",
        "              data: torch.utils.data.DataLoader,\n",
        "              acc_fn: any,\n",
        "              loss_fn: torch.nn,\n",
        "              device: torch.device = DEVICE_DESTINATION):\n",
        "  \"\"\"Performs a testing loop step on model going over data_loader\"\"\"\n",
        "  model.eval()\n",
        "  loss, acc = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for X, y in data:\n",
        "      # 0. Data into device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # 1. Forward pass\n",
        "      y_pred = model(X)\n",
        "\n",
        "      # 2. Calculate the loss and acc\n",
        "      loss += loss_fn(y_pred, y)\n",
        "      acc += acc_fn(y_pred.argmax(dim=1), y)\n",
        "\n",
        "    loss /= len(data)\n",
        "    acc /= len(data)\n",
        "    print(f\"Test loss: {loss:.4f} | Test acc: {acc:.4f}%\\n\")"
      ],
      "metadata": {
        "id": "0EJTB9Aa8Pkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "train_time_start_on_gpu = timer()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f'Epoch {epoch}\\n -----')\n",
        "  train_step(model=model_1,\n",
        "             data=train_dataloader,\n",
        "             loss_fn=loss_fn,\n",
        "             acc_fn=accuracy_fn,\n",
        "             optimizer=optimizer,\n",
        "             device=DEVICE_DESTINATION)\n",
        "\n",
        "  test_step(model=model_1,\n",
        "            data=test_dataloader,\n",
        "            acc_fn=accuracy_fn,\n",
        "            loss_fn=loss_fn,\n",
        "            device=DEVICE_DESTINATION)\n",
        "\n",
        "train_time_end_on_gpu = timer()\n",
        "total_train_time_model_1 = time_start_end(start_time = train_time_start_on_gpu,\n",
        "               end_time=train_time_end_on_gpu,\n",
        "                                          device=next(model_1.parameters()).device)"
      ],
      "metadata": {
        "id": "8Yzd8kX1FBgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GPU time: {total_train_time_model_1} seconds\")"
      ],
      "metadata": {
        "id": "RcIWXoy4FTGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"GPU time: {total_train_time_model_0} seconds\")"
      ],
      "metadata": {
        "id": "-vDR-626IcN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results = eval_mode(data=test_dataloader,\n",
        "                            model=model_1,\n",
        "                            loss_fn=loss_fn,\n",
        "                            acc_fn=accuracy_fn,\n",
        "                            device='cuda')"
      ],
      "metadata": {
        "id": "bHULUrhDKyfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0_results"
      ],
      "metadata": {
        "id": "iw9TKRBbM3Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1_results"
      ],
      "metadata": {
        "id": "Gb-MCcr1MFXi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}