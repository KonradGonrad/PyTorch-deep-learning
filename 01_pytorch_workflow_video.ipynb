{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Workflow\n",
        "\n",
        "Resources:\n",
        "- notebook: https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
        "- website: https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "- questions: https://github.com/mrdbourke/pytorch-deep-learning/discussions"
      ],
      "metadata": {
        "id": "YDPhWmt-Cpgd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuXXhZlKBqH_"
      },
      "outputs": [],
      "source": [
        "what_were_covering = {1: 'data covering into tensors (prepare and load)',\n",
        "                      2: 'build or pick model',\n",
        "                      3: 'fitting model to data (training)',\n",
        "                      4: 'making predictions and evaluating a model',\n",
        "                      5: 'saving and loading model',\n",
        "                      6: 'combining everything and saving model to reload'}\n",
        "\n",
        "what_were_covering"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn # nn = neutral network, PyTorch's building blocks\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# check PyTorch version\n",
        "\n",
        "torch.__version__"
      ],
      "metadata": {
        "id": "OBZj4KvVDjMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Preparing and loading data\n",
        "\n",
        "data can be almost everything, what we can present in numeric representation, in Machine Learning\n",
        "\n",
        "For example:\n",
        "- Excel spreadsheet\n",
        "- Images of any kind\n",
        "- Videos, Youtube\n",
        "- Audio, like songs or podcasts\n",
        "- Text\n",
        "- Dna\n",
        "\n",
        "Machine learning is a game of two parts:\n",
        "1. Get data into a numerical representation\n",
        "2. Build a model to learn patterns in numerical representation"
      ],
      "metadata": {
        "id": "1dhlRPvvEMS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Creating data\n",
        "\n",
        "# Create *known* parameters\n",
        "# linear function formula: Y = a + bX; a = bias, b = weight\n",
        "\n",
        "weight = 0.7 #waga, siła połączeń między neuronami\n",
        "bias = 0.3  #błąd systematyczny\n",
        "\n",
        "# Create data\n",
        "start = 0\n",
        "end = 1\n",
        "step = 0.02\n",
        "X = torch.arange(start, end, step).unsqueeze(dim=1) # tensor, matrix\n",
        "y = weight * X + bias #linear function\n",
        "\n",
        "# show data\n",
        "print(f\"X tensor (first ten):\\n {X[:10]}\")\n",
        "print(f\"y tensor (first ten):\\n {y[:10]}\")\n",
        "print(f\"length of X: {len(X)} and len of y: {len(y)}\")"
      ],
      "metadata": {
        "id": "rHc64PoWEGHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data into training and test sets, what is one of the most important concepts in Machine Learning"
      ],
      "metadata": {
        "id": "vp79pnmFHFXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train/test split\n",
        "train_split = int(0.8 * len(X))\n",
        "X_train, y_train = X[:train_split], y[:train_split]\n",
        "X_test, y_test = X[train_split:], y[train_split:]\n",
        "\n",
        "len(X_train), len(X_test)"
      ],
      "metadata": {
        "id": "lFh8zGpzIecI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizating data"
      ],
      "metadata": {
        "id": "0vSPZT0ASNgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_predictions(train_data = X_train,\n",
        "                     train_labels = y_train,\n",
        "                     test_data = X_test,\n",
        "                     test_labels = y_test,\n",
        "                     predictions = None):\n",
        "  \"\"\"\n",
        "  Plots training data\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "\n",
        "  # Plot training data in blue\n",
        "  plt.scatter(train_data, train_labels, c='b', s=4, label='Trainining data')\n",
        "\n",
        "  # Plot test data in green\n",
        "  plt.scatter(test_data, test_labels, c='g', s=4, label='Testing data')\n",
        "\n",
        "  # Are there predictions?\n",
        "  if predictions is not None:\n",
        "    # Plot predictions\n",
        "    plt.scatter(test_data, predictions, c='r', s=4, label='Predictions')\n",
        "\n",
        "  # Show the legend\n",
        "  plt.legend(prop={\"size\": 14})"
      ],
      "metadata": {
        "id": "mYikkv06Toz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions()"
      ],
      "metadata": {
        "id": "d05vAEOTT56N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building PyTorch model\n",
        "\n",
        "OOP: https://realpython.com/python3-object-oriented-programming/\n",
        "\n",
        "What Model does:\n",
        "- start with random values of weight and bias\n",
        "- Check training data and adjust the random values to get closer to ideal values\n",
        "\n",
        "How does it do so:\n",
        "two main algorithms:\n",
        "1. gradient descent: https://www.youtube.com/watch?v=IHZwWFHWa-w\n",
        "2. backpropagation: https://www.youtube.com/watch?v=Ilg3gGewQ5U\n"
      ],
      "metadata": {
        "id": "19v-hdMLVUAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "# Create linear regression model class\n",
        "class LinearRegressionModel(nn.Module): # nn.Module is lego building blocks for PyTorch\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weights = nn.Parameter(torch.randn(1,\n",
        "                                           requires_grad = True,\n",
        "                                           dtype = torch.float))\n",
        "    self.bias = nn.Parameter(torch.randn(1,\n",
        "                                         requires_grad = True,\n",
        "                                         dtype=torch.float))\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor: # \"x\" is the input data\n",
        "    return self.weights * x + self.bias\n"
      ],
      "metadata": {
        "id": "ezbhPy2CWLZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from sys import modules\n",
        "### PyTorch model building essentials\n",
        "\n",
        "* torch.nn - contains all of the buildings for computational graphs (neural network)\n",
        "* torch.nn.Parameter - what parameters should our model try and learn\n",
        "* torch.nn.Module - the bvase class for all neural network modules\n",
        "* torch.optim - optimalize parameters to pronouce better results\n",
        "* def forward() - All nn.Module subclasses require to overwrite forward(), this emtod defines what happens in the forward computation\n",
        "* torch.util.data.Dataset -\n",
        "* torch.utils.data.DataLoader -"
      ],
      "metadata": {
        "id": "WsEh3inBpUf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# What's inside our model\n",
        "\n",
        "# we can check our model parameters or what's inside by using '.parameters()'\n",
        "\n",
        "# random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# instance of the model\n",
        "model_0 = LinearRegressionModel()\n",
        "\n",
        "# check parameters\n",
        "list(model_0.parameters())"
      ],
      "metadata": {
        "id": "4NGhGnvBpUQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List named parameters\n",
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "fyVKPyjSy5Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# goal is to get close to this values\n",
        "weight, bias"
      ],
      "metadata": {
        "id": "hjzkKYNdz8P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making predictions with our model with 'torch.inference_mode()'\n",
        "\n",
        "To check our model's predictive power, let's see how well it predicts y_test based on X_test\n",
        "\n",
        "When we pass data through model, it's going to run it thorugh the forward() method."
      ],
      "metadata": {
        "id": "MwdpNVIc0JLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "with torch.inference_mode():\n",
        "  y_preds = model_0(X_test)\n",
        "\n",
        "y_preds"
      ],
      "metadata": {
        "id": "HrsVVONF0fgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_preds)"
      ],
      "metadata": {
        "id": "AMVSp3Xo1NKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model\n",
        "\n",
        "the whole idea of training model is to evelop random parameters into parameters, which are as close as they can to *known* parameters\n",
        "\n",
        "One way to measure how poor or how bad our models predictions are is to use pytorch loss functions\n",
        "\n",
        "* Note: Loss function may also be called cost function or criterion in different areas\n",
        "\n",
        "Thing we need to train:\n",
        "\n",
        "* **Loss functions:** A function to measure how wrong model's predictions are\n",
        "\n",
        "* **Optimizer** takes into account the loss of a model and adjust the model's parameters (e.g weight and bias in our case) to improve the loss function\n",
        "\n",
        "For PyTorch we need:\n",
        "* A training loop\n",
        "* A testing loop"
      ],
      "metadata": {
        "id": "upze2oht2VA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a loss function\n",
        "loss_fn = nn.L1Loss()\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = torch.optim.SGD(params = model_0.parameters(),\n",
        "                            lr = 0.01) # lr = learning rate = possibly the most important hyperparameter you can set"
      ],
      "metadata": {
        "id": "ogAyurk14EY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn"
      ],
      "metadata": {
        "id": "HsUuK0UA6pM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a training loop (and a testing loop) in PyTorch\n",
        "\n",
        "A couple of things we need in a training loop:\n",
        "0. Loop through data and do:\n",
        "1. Forward pass (this involves data moving through our model's forward()' function) to make predictions on data\n",
        "2. calculate the loss (compare forward pass predictions to ground truth labels)\n",
        "3. Optimizer zero grad\n",
        "4. Loss backward - move backwards through the network to calculate the gradients of each of the parameters of our model with respect to the loss\n",
        "5. Optimizer step - use the optimizer to adjust our model's parameters to try and improve the loss (**gradient descent**)"
      ],
      "metadata": {
        "id": "fqfXjzTO6rE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "u83kfEaXSj5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# An epoch is one loop thorugh the data\n",
        "epochs = 200\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "# Track different values with tracking progress\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "test_loss_values = []\n",
        "#Training\n",
        "# 0. loop through data for a number of epochs\n",
        "for epoch in range(epochs):\n",
        "  # Song:\n",
        "  # It's train time!\n",
        "  # Do the forward pass,\n",
        "  # Calculate the loss\n",
        "  # optimizer zero grad,\n",
        "  # loss backwards\n",
        "  #\n",
        "  # Optimizer step step step\n",
        "  #\n",
        "  # Let's test now!\n",
        "  # With torch no grad:\n",
        "  # do the forward pass\n",
        "  # calculate the loss\n",
        "  # watch it go down down down\n",
        "\n",
        "  model_0.train() # train mode sets all parameters that require gradients to require gradients\n",
        "\n",
        "  # 1. Forward pass with training data\n",
        "  y_pred = model_0.forward(X_train)\n",
        "\n",
        "  # 2. Calculate the loss (how our model's prediction are wrong to correct answears)\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "  # 3. Optimimizer zero grad\n",
        "  optimizer.zero_grad() # reset grad ( beacouse grad accumulate after a few loops )\n",
        "\n",
        "  # 4. Loss backward (backpropagation na bazie grad dla każdego elementu; zmienia potencjalnie wagi lub bias, aby zblizyc sie do docelowego inputu)\n",
        "  loss.backward()\n",
        "\n",
        "  # 5. Step the optimizer\n",
        "  optimizer.step() # taking a \"step\" to update values of our parameters to perform closer output\n",
        "\n",
        "  # model_0.eval() - wyłącza śledzenie gradientu\n",
        "  model_0.eval() # wyłącza niepotrzebne funkcje\n",
        "  with torch.inference_mode(): # turns off gradient tracking & a couple more things\n",
        "    # 1 forward mode\n",
        "    test_pred = model_0(X_test)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    epoch_count.append(epoch)\n",
        "    loss_values.append(loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "    print(f\"Epoch: {epoch} | loss: {loss} | Test loss: {test_loss}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MArMcpSeSS5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the loss curves\n",
        "plt.plot(epoch_count, np.array(torch.tensor(loss_values)),label = 'Loss value')\n",
        "plt.plot(epoch_count, test_loss_values, label='Test loss value')\n",
        "plt.legend()\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.title('Training and test loss accuracy')"
      ],
      "metadata": {
        "id": "aauPeYj4lr4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.state_dict()"
      ],
      "metadata": {
        "id": "nI3z3NlZTdmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight, bias"
      ],
      "metadata": {
        "id": "_4GrPbNKYLHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.inference_mode():\n",
        "  y_pred_new = model_0(X_test)\n"
      ],
      "metadata": {
        "id": "UFLbmVoZYse-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_preds)"
      ],
      "metadata": {
        "id": "_ZK98V6WZxzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(predictions = y_pred_new)"
      ],
      "metadata": {
        "id": "JDzcyZwrZq1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving a model in PyTorch\n",
        "\n",
        "There are three main methods you should know about for saving and loading models in PyTorch.\n",
        "\n",
        "1. 'torch.save()' - allows to save a PyTorch object in Python pickle format\n",
        "2. 'torch.load()' - allows to load a saved PyTorch object\n",
        "3. 'torch.nn.Module.load_state_dict()' - allows to load a model's saved state dictionary; to simplify that loads parameters with \"weights\"\n"
      ],
      "metadata": {
        "id": "F0wE-thHZt3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# 1. Creating model directory\n",
        "MODEL_DIRECTORY = Path(\"Models\")\n",
        "MODEL_DIRECTORY.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# 2. Create model save path\n",
        "MODEL_NAME = \"01_pytorch_model.pth\"\n",
        "MODEL_SAVING = MODEL_DIRECTORY / MODEL_NAME\n",
        "\n",
        "# 3. Save the model state dict\n",
        "print(f\"Model saved to {MODEL_DIRECTORY}/{MODEL_NAME}\")\n",
        "torch.save(obj=model_0.state_dict(),\n",
        "           f=MODEL_SAVING)"
      ],
      "metadata": {
        "id": "PFcVZJIP81Gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model from saved copy\n",
        "\n",
        "# 1. Creating empty model class\n",
        "loaded_model = LinearRegressionModel()\n",
        "\n",
        "# 2. Loading model state dict from saved model directory\n",
        "loaded_model.load_state_dict(torch.load(MODEL_SAVING))\n",
        "\n",
        "# Checking if is everything all right loaded\n",
        "loaded_model.state_dict()"
      ],
      "metadata": {
        "id": "W7WF96J-3cTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions:\n",
        "loaded_model.eval()\n",
        "with torch.inference_mode():\n",
        "  loaded_model_pred = loaded_model(X_test)\n",
        "np.array(torch.tensor(loaded_model_pred))\n",
        "plot_predictions(predictions= np.array(torch.tensor(loaded_model_pred)))"
      ],
      "metadata": {
        "id": "WDl6OsJZ7hRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare loaded model preds with original model\n",
        "\n",
        "loaded_model_pred == y_pred_new"
      ],
      "metadata": {
        "id": "NEHWVvHJCb7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Puttint it all together\n"
      ],
      "metadata": {
        "id": "EkPk0KnJDQV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1 Data"
      ],
      "metadata": {
        "id": "tNffAwo3KHcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "53hmdtPwKLOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create device agnostic code\n",
        "device_destination = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device_destination"
      ],
      "metadata": {
        "id": "Eq9wvRHJKssA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create data with random state\n",
        "\n",
        "# Create known values as weight and bias\n",
        "weight = 0.7\n",
        "bias = 0.3\n",
        "\n",
        "# Data\n",
        "RANDOM_STATE = 42\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "# number settings\n",
        "start = 0\n",
        "end = 1.0\n",
        "step = 0.01\n",
        "\n",
        "# creating random numbers for data\n",
        "x = torch.arange(start= start, end= end, step = step).unsqueeze(dim=1)\n",
        "y = weight * x + bias # y = wx + b\n",
        "\n",
        "# summing up what we have done\n",
        "print(f\"Our x ranges from {start} to {end} with {step} step\")\n",
        "print(f\"length of x: {len(x)} | length of y: {len(y)}\")"
      ],
      "metadata": {
        "id": "-FyRDAaZKysP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create train and test data\n",
        "train_percentage = 80\n",
        "portion = int((train_percentage) * 0.01 * len(x))\n",
        "\n",
        "X_train, y_train, X_test, y_test = x[:portion], y[:portion], x[portion:], y[portion:]\n",
        "\n",
        "print(f\"our dataset was splitted to {train_percentage}% train and {100 - train_percentage}% test\")\n",
        "print(f\"train size: {len(X_train)} | test size: {len(X_test)}\")"
      ],
      "metadata": {
        "id": "ly6hUNv2OMpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model\n",
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.linear_layer = nn.Linear(in_features=1,\n",
        "                                  out_features=1)\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "    return  self.linear_layer(x)"
      ],
      "metadata": {
        "id": "WK6S75SVPSuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(RANDOM_STATE)\n",
        "module_01 = LinearRegressionModel()\n",
        "module_01.state_dict()"
      ],
      "metadata": {
        "id": "SiH66wD5eUpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(module_01.parameters()).device"
      ],
      "metadata": {
        "id": "YbuO44NPkgHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_01.to(device_destination)\n",
        "next(module_01.parameters()).device"
      ],
      "metadata": {
        "id": "F9W9DKzNkn-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pyplot visualization function\n",
        "\n",
        "def plot_prediction(X_train = X_train,\n",
        "                    y_train = y_train,\n",
        "                    X_test = X_test,\n",
        "                    y_pred = None):\n",
        "  plt.figure(figsize=(10, 7))\n",
        "  plt.scatter(X_train, y_train, s=10, label = 'Train data')\n",
        "  plt.scatter(X_test, y_test, s=10, label = 'Test data')\n",
        "\n",
        "  if not (y_pred == None):\n",
        "    plt.scatter(X_test, y_pred, s=10, label = 'Predictions')\n",
        "\n",
        "  plt.legend()\n",
        "  plt.title('Model predictions compared to test and train data')"
      ],
      "metadata": {
        "id": "sm3b6f_qLBvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction()"
      ],
      "metadata": {
        "id": "2sLcqJWDfoLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.L1Loss()"
      ],
      "metadata": {
        "id": "RFHOA8lIqKc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "optimizer = torch.optim.SGD(params = module_01.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "q48L4YF4qXPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train device: {X_train.device} | y_train device: {y_train.device} | module_01 device: {module_01.parameters}\")"
      ],
      "metadata": {
        "id": "w4fKWImHt5Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "torch.manual_seed(RANDOM_STATE)\n",
        "\n",
        "# Put data on correct device\n",
        "X_train = X_train.to(device_destination)\n",
        "X_test = X_test.to(device_destination)\n",
        "y_train = y_train.to(device_destination)\n",
        "y_test = y_test.to(device_destination)\n",
        "\n",
        "\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  module_01.train()\n",
        "\n",
        "  # Forward pass\n",
        "  y_pred = module_01(X_train)\n",
        "\n",
        "  # Calculate the loss\n",
        "  loss = loss_fn(y_pred, y_train)\n",
        "\n",
        "  # Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # loss backward\n",
        "  loss.backward()\n",
        "\n",
        "  # Optimizer step step step\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  module_01.eval()\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    test_pred = module_01.forward(X_test)\n",
        "\n",
        "    test_loss = loss_fn(test_pred, y_test)\n",
        "\n",
        "  # Print out\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"epoch: {epoch} | loss: {loss} | test_loss: {test_loss}\")\n"
      ],
      "metadata": {
        "id": "8yFx8J7jLoAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_01.state_dict()"
      ],
      "metadata": {
        "id": "meS2_i_isoZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.device)\n",
        "print(X_test.device)\n",
        "print(y_test.device)\n",
        "print(X_train.device)\n",
        "print(y_train.device)"
      ],
      "metadata": {
        "id": "VyHfDa9PrwAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_cpu(*args: torch.Tensor) -> torch.Tensor:\n",
        "  args = args.to('cpu')\n",
        "  return args"
      ],
      "metadata": {
        "id": "tzZiVGgnwwau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_preds.to('cuda')"
      ],
      "metadata": {
        "id": "I_SllyXrxTM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2fVNq9PxOBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_01.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_preds = module_01(X_test)\n",
        "\n",
        "y_preds = y_preds.to('cpu')\n",
        "X_train = X_train.to('cpu')\n",
        "y_train = y_train.to('cpu')\n",
        "X_test = X_test.to('cpu')\n",
        "y_test = y_test.to('cpu')"
      ],
      "metadata": {
        "id": "1qcq_OVnr6PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_prediction(y_pred = y_preds)"
      ],
      "metadata": {
        "id": "sjjk85uGsPfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model\n",
        "from pathlib import Path\n",
        "PATH = Path('Models')\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "NAME = 'Module_01.saved_version_1.pt'\n",
        "DIRECTORY_PATH = PATH / NAME\n",
        "torch.save(module_01.state_dict(), DIRECTORY_PATH)"
      ],
      "metadata": {
        "id": "V68PsVxSN57N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_01_loaded = LinearRegressionModel()\n",
        "\n",
        "module_01_loaded.load_state_dict(torch.load(DIRECTORY_PATH))\n",
        "module_01_loaded.state_dict()\n",
        "module_01_loaded.to(device_destination)"
      ],
      "metadata": {
        "id": "lnhuPXCAOp4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "module_01_loaded.eval()\n",
        "\n",
        "with torch.inference_mode():\n",
        "  y_pred_loaded = module_01_loaded(X_test)\n",
        "  plot_prediction(X_train, y_train, X_test, y_pred_loaded)"
      ],
      "metadata": {
        "id": "bbjZg4kUQhY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_loaded == y_preds"
      ],
      "metadata": {
        "id": "F8hJzqcSQ5JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excercuses & Extra-curriculum\n",
        "\n",
        "for excercise & extra-curriculum we can use:\n",
        "  - https://www.learnpytorch.io/01_pytorch_workflow/#extra-curriculum\n",
        "  - https://www.learnpytorch.io/01_pytorch_workflow/#exercises\n",
        "  - https://github.com/mrdbourke/pytorch-deep-learning/tree/main/extras/exercises"
      ],
      "metadata": {
        "id": "1RfWP0VRUMy3"
      }
    }
  ]
}