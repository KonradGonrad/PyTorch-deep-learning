{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPbpik/caeoC+REeTwgJysu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradGonrad/PyTorch-deep-learning/blob/main/04_pytorch_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets"
      ],
      "metadata": {
        "id": "D1I-4kerC9Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "u-7OAiumDSY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmroY6yZ0oVN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# PyTorch 1.10 +\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "DEVICE_DESTINATION = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE_DESTINATION"
      ],
      "metadata": {
        "id": "pfjq-9K_DqZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data"
      ],
      "metadata": {
        "id": "SgNbhPL3EBw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "images_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it\n",
        "if images_path.is_dir():\n",
        "  print(f\"{images_path} already exist. Skipping download...\")\n",
        "else:\n",
        "  print(f\"Creating {images_path} path\")\n",
        "  images_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", 'wb') as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", 'r') as ziprep:\n",
        "  print(\"Extracking pizza_steak_sushi data...\")\n",
        "  ziprep.extractall(images_path)\n"
      ],
      "metadata": {
        "id": "aCsG-XGzEJyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Becoming one with the data (Data preparation and data exploration)\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"there are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "VMTUdXa486yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(images_path)"
      ],
      "metadata": {
        "id": "ej5XXmkqKaJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training and testing part\n",
        "train_dir = images_path / \"train\"\n",
        "test_dir = images_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "jcId2mO_KdKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Visualizing an image\n",
        "\n",
        "1. Get all of the image paths\n",
        "2. Pick a random image path using python's random.choice()\n",
        "3. Get the image class name 'pathlib.Path.parent.stem'\n",
        "4. Since we're working with images, let's open the image with Python's PIL\n",
        "5. We'll then show the image and print metadata"
      ],
      "metadata": {
        "id": "UFD8bcNXK5TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "#random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. Open image with Python PIL\n",
        "img = Image.open(random_image)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image}\")\n",
        "print(f\"Random image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "5OSCOsZgRnU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize image with matplotlib - mine approach\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Set seed\n",
        "#random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. from random_path into 3 dimension (rgb) image\n",
        "image = mpimg.imread(random_image)\n",
        "\n",
        "# Visualize image with matplotlib\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(False)\n",
        "plt.title(image_class)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VulKJzGtSpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize image with matplotlib - video approach\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. Open image with Python PIL\n",
        "img = Image.open(random_image)\n",
        "\n",
        "# 5. Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# 6. Plot the image\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color channels] (HWC)\")\n",
        "plt.axis(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ONJC07AgYEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforming data\n",
        "\n",
        "Before we can use our image data with PyTorch:\n",
        "1. Turn your target data into tensors (in our case, numerical representation of our images)\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'l call these `Dataset` and `Dataloader`"
      ],
      "metadata": {
        "id": "iPoTSkJ-p0EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "ZBKuyVP630nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Transforming data with `torchvision.transforms`"
      ],
      "metadata": {
        "id": "V1c9Wtwq37C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our images to 64x64\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    # Turn the image into a torch tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "rcceh8Lh3-WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "4kGXJ93D5lt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths: list, transform, n=3, seed=None):\n",
        "  \"\"\"\n",
        "  Selects random images from a path of images and loads/transforms them\n",
        "  then plots the original vs transformed version\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    random.seed(42)\n",
        "  random_image_paths = random.sample(image_paths, k=n)\n",
        "  for random_image in random_image_paths:\n",
        "    with Image.open(random_image) as f:\n",
        "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].axis(False)\n",
        "      ax[0].set_title(f\"Original size: {f.size}\")\n",
        "\n",
        "      transformed_f = transform(f).permute(1, 2, 0)\n",
        "      ax[1].imshow(transformed_f)\n",
        "      ax[1].axis(\"off\")\n",
        "      ax[1].set_title(f\"Shape: {transformed_f.shape}\")\n",
        "\n",
        "      fig.suptitle(f\"Class: {random_image.parent.stem}\", fontsize=16)\n",
        "plot_transformed_images(image_paths,\n",
        "                        data_transform,\n",
        "                        n=3,\n",
        "                        seed=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "1gAFUxkd5qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Loading image data using ImageFolder\n",
        "We can load image classification data using `torchvision.datasets.ImageFolder`"
      ],
      "metadata": {
        "id": "bOJX6N70JA85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create dataset's\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform,\n",
        "                                 target_transform=None)\n",
        "\n",
        "print(train_data, test_data)"
      ],
      "metadata": {
        "id": "WAmSNJJUXK92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "6WixAdYMX1C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "10Zv_CsAiW8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of our dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "cLyXaI_f9oZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "SYbTOX_A9yl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on the train_data Dataset to get a single image and label\n",
        "import random\n",
        "\n",
        "random_idx = random.randint(0, len(train_data))\n",
        "img, label = train_data[random_idx][0], train_data[random_idx][1]\n",
        "print(f\"Image tensor:\\n {img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "Pk_9CIrN92tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "0KGyah0f-XOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Label: {label} which one is {class_names[label]}\")"
      ],
      "metadata": {
        "id": "66jVCgk7-j3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "print(f\"old shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"new shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y7I7njFw-kYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Turn loaded images into `DataLoaders's`\n",
        "\n",
        "A `Dataloader` is going to help us turn our `Dataset`'s into iterables and we can see `batch_size` images at a time"
      ],
      "metadata": {
        "id": "FmW3wqlmBCtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=os.cpu_count(),\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "nI9sl87U_TlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "YoBSX3oqA5x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"image shape: {img.shape} -> [batch_size, color_channles, height, width]\")\n",
        "print(f\"label shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "0mtPJQA9F8l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Option 2: Loading Image data with a custom `dataset`\n",
        "\n",
        "1. Want to be able to load images from file\n",
        "2. Want to be able to get class names from the dataset\n",
        "3. Want to be able to get classes as dictionary from the dataset\n",
        "\n",
        "Pros:\n",
        "* Can create a `Dataset` out of almost anything\n",
        "* Non limited to PyTorch pre-built `Dataset` functions\n",
        "\n",
        "Cons:\n",
        "* Even though you could create `Dataset` out of almost anything, it doesn't mean it will work\n",
        "* Using a custom `Dataset` often results in us writing more code, which could be prone to errors or performance issues\n",
        "\n",
        "All custom datasets in PyTorch, often subclass `torch.utils.data.Dataset`"
      ],
      "metadata": {
        "id": "HngBoixTGKoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "jF-LPWqWUsks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "FsRc4qZMVgTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Creating a helper function to get class names\n",
        "\n",
        "We want a function to:\n",
        "1. Get the class names using 'os.scandir()' to traverse a taget directory (ideally the directory is in standart image classification format).\n",
        "2. Raise and error if the class names aren't found (ig this happens, there might be something wrong with the directory structure)\n",
        "3. Turn the class names into a dict and a list and return them"
      ],
      "metadata": {
        "id": "AF6Q4gH0Vmrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for target directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target dir: {target_directory}\")\n",
        "\n",
        "# Get the class names from the target directory\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "gU7RdlaMWie8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "-9BEIpIsWqWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "  \"\"\"\n",
        "  Finds the class folder names in a target directory.\n",
        "  \"\"\"\n",
        "  # 1. Get the class names by scanning the target directory\n",
        "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "  # 2. Raise an error if class names could not be found\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}...\")\n",
        "\n",
        "  # 3. Create a dictionary of index labels (computers prefer numbers rather than string as labels)\n",
        "  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "mESOw5hOXILj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "1iNBekQjX306"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['Konrad', 'Kamil', 'Wojtek']\n",
        "list((name, i) for i, name in enumerate(x))"
      ],
      "metadata": {
        "id": "e5fD2TxDYGiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Create a custom `Dataset` to replicate `ImageFolder`\n",
        "\n",
        "To create our own custom dataset, we want to:\n",
        "\n",
        "1. Subclass `torch.utils.data.Dataset`\n",
        "2. Init our subclass with a target directory (the directory we'd like to get data from) as well as a transform if we'd like to transform our data.\n",
        "3. Create several attributes:\n",
        " * paths - paths of our images\n",
        " * transform - the transform we'd like to use\n",
        " * classes - a list of the target classes\n",
        " * class_to_idx - a dict of the target classes mapped to integer labels\n",
        "4. Create a function to `load_images()`, this function will open an image\n",
        "5. Overwrite the `__len__()` method to return the length of our dataset\n",
        "6. Overwrite the `__getitem()__` method to return a given sample when passed an index"
      ],
      "metadata": {
        "id": "MupGgSoWY5oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a custom dataset class\n",
        "from torch.utils.data import Dataset\n",
        "import pathlib\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(Dataset):\n",
        "  # 2. initialize our custom dataset\n",
        "  def __init__(self,\n",
        "               targ_dir,\n",
        "               transform = None):\n",
        "    # 3. Create class atributes\n",
        "    self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
        "    # Setup transform\n",
        "    self.transform = transform\n",
        "    # Create classes and class_to_idx\n",
        "    self.class_names, self.class_to_idx = find_classes(targ_dir)\n",
        "\n",
        "  # 4. Create a function to load images\n",
        "  def load_images(self, index: int) -> Image.Image:\n",
        "    \"Opens an image via a path and returns it\"\n",
        "    image_path = self.paths[index]\n",
        "    return Image.open(image_path)\n",
        "\n",
        "  # 5. Overwrite the __len__()\n",
        "  def __len__(self) -> int:\n",
        "    \"Returns the total number of samples\"\n",
        "    return len(self.paths)\n",
        "\n",
        "  # 6. Overwrite the __getitem__()\n",
        "  def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "    \"Returns one sample of data, data and label (X, y)\"\n",
        "    img = self.load_images(index)\n",
        "    class_name = self.paths[index].parent.name\n",
        "    class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "    # Transform if necesarry\n",
        "    if self.transform:\n",
        "      return self.transform(img), class_idx\n",
        "    else:\n",
        "      return img, class_idx\n"
      ],
      "metadata": {
        "id": "QeAPOXq2SYQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a transform\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "YY4gN-3tVl4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out ImageFolderCustom\n",
        "train_data_custom = ImageFolderCustom(targ_dir=train_dir,\n",
        "                                      transform=train_transforms)\n",
        "\n",
        "test_data_custom = ImageFolderCustom(targ_dir=test_dir,\n",
        "                                     transform=test_transforms)"
      ],
      "metadata": {
        "id": "zVKv6D0MgsCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom, test_data_custom"
      ],
      "metadata": {
        "id": "KchcFssmrdVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(train_data_custom)"
      ],
      "metadata": {
        "id": "HzLaaMtrsUdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_data), len(test_data_custom)"
      ],
      "metadata": {
        "id": "bPTPzjivsbwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_names, train_data.classes"
      ],
      "metadata": {
        "id": "ulrTtN9Asfj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.class_to_idx, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "_gT7n20Vshe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_custom.paths"
      ],
      "metadata": {
        "id": "_RN5ysDesqaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for equality between original ImageFolder Dataset and ImageFolderCustomDataset\n",
        "print(train_data_custom.class_names == train_data.classes)\n",
        "print(test_data_custom.class_names == test_data.classes)"
      ],
      "metadata": {
        "id": "TaeZinoMsvE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.3 Create a function to display random images\n",
        "\n",
        "1. Take in a `Dataset` and a number of other parameters as class names and how many images to Visualize\n",
        "2. To prevent the display getting out of hand, let's cap the number of images to see at 10\n",
        "3. Set the random seed for reproducibility\n",
        "4. Get a list of random sample indexes from the target dataset\n",
        "5. Setup a matplotlib plot\n",
        "6. Loop through the random sample images and plot them with plt.matplotlib\n",
        "7. Make suer the dimensions of our image line up with matplotlib (HWC)\n"
      ],
      "metadata": {
        "id": "u6cDN5gKtI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a function to take in a dataset\n",
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                          classes: List[str] = None,\n",
        "                          n: int = 10,\n",
        "                          display_shape: bool = True,\n",
        "                          seed: int = None):\n",
        "  # 2. Adjust display if n is to high\n",
        "  if n > 10:\n",
        "    print(f\"Due to too high n, what may cause problems with visualization, n is set to 10 instead of {n}\")\n",
        "    display_shape = False\n",
        "    n = 10\n",
        "\n",
        "  # 3. Set the seed\n",
        "  if seed:\n",
        "    random.seed(seed)\n",
        "\n",
        "  # 4. Get random sample indexes\n",
        "  random_sample_idx = random.sample(range(len(dataset)), k=n)\n",
        "\n",
        "  # 5. Setup plot\n",
        "  plt.figure(figsize=(16,8))\n",
        "\n",
        "  # 6. Loop through random indexes and plot them with matplotlib\n",
        "  for i, targ_image in enumerate(random_sample_idx):\n",
        "    image, label = dataset[targ_image][0], dataset[targ_image][1]\n",
        "\n",
        "    # 7.Adjust tensor dimensions for plotting\n",
        "    image_adjust = image.permute(1, 2, 0)\n",
        "\n",
        "    # Plot adjusted samples\n",
        "    plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(image_adjust)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    if classes:\n",
        "      title = f\"Class: {classes[label]}\"\n",
        "      if display_shape:\n",
        "        title = title + f\"\\nshape: {image_adjust.shape}\"\n",
        "    plt.title(title)\n",
        "\n"
      ],
      "metadata": {
        "id": "b1NtWF6muEBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display random images\n",
        "display_random_images(train_data,\n",
        "                      n=4,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ],
      "metadata": {
        "id": "a4C6RHUFvASO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_random_images(train_data_custom,\n",
        "                      n=5,\n",
        "                      classes=class_names,\n",
        "                      seed=42)"
      ],
      "metadata": {
        "id": "DdQ_Aepd03VE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.4 Turn Custom loaded images into `DataLoader's`"
      ],
      "metadata": {
        "id": "eUV3u92U9n0A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=True)\n",
        "\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    num_workers=NUM_WORKERS,\n",
        "                                    shuffle=False)\n",
        "\n",
        "train_dataloader_custom"
      ],
      "metadata": {
        "id": "-YaCDe8A-JT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get image and label from custom dataloader\n",
        "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "# Print out the shapes\n",
        "img_custom.shape, label_custom.shape"
      ],
      "metadata": {
        "id": "bXdxoOfO-wr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Other forms of transforms (data augmentation)\n",
        "\n",
        "Data augmentation is the process fo artificially adding diversity to your training data.\n",
        "\n",
        "In the case of image data, this may mean applying various image transformations to the training images\n",
        "\n",
        "`It's something like looking on the same image but from different perspectives`\n",
        "\n",
        "Let's take a look at one particular type of data augmentation used to train PyTorch vision models to state of the art levels\n"
      ],
      "metadata": {
        "id": "_oEP3vmk_FKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at trivailaugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "NA4ZJAwPrlfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image paths\n",
        "image_path_list = list(pathlib.Path(data_path / \"pizza_steak_sushi\").glob('*/*/*.jpg'))\n",
        "image_path_list[:10]"
      ],
      "metadata": {
        "id": "r-kB5Ar6s90g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot random transformed images\n",
        "plot_transformed_images(\n",
        "    image_paths=image_path_list,\n",
        "    transform=train_transform,\n",
        "    n=3,\n",
        "    seed=None\n",
        ")"
      ],
      "metadata": {
        "id": "PaZX2JwBtYmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model -: TinyVGG without data augmentation\n",
        "Let's replicate TinyVGG architecture from the ccn explainer"
      ],
      "metadata": {
        "id": "_DNYye31uCNV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.1 Creating transforms and loading data for Model 0"
      ],
      "metadata": {
        "id": "PwN9m4tmvFPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create simple transform\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "Zpv7d779vYQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "train_data = list(train_and_test_path.glob('train/*/*.jpg'))\n",
        "test_data = list(train_and_test_path.glob('test/*/*.jpg'))"
      ],
      "metadata": {
        "id": "zEBczsb5vs12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and transform data\n",
        "from torchvision import datasets\n",
        "train_data_simple = datasets.ImageFolder(root=train_dir,\n",
        "                                         transform=simple_transform)\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                        transform=simple_transform)\n",
        "\n",
        "# 2. Turn the datasets into DataLoaders\n",
        "import os\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setup batch size and number of workers\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Create DataLoader's\n",
        "train_dataloader_simple = DataLoader(train_data_simple,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     shuffle=True,\n",
        "                                     num_workers=NUM_WORKERS)\n",
        "\n",
        "test_dataloader_simple = DataLoader(test_data_simple,\n",
        "                                    batch_size=BATCH_SIZE,\n",
        "                                    shuffle=False,\n",
        "                                    num_workers=NUM_WORKERS)"
      ],
      "metadata": {
        "id": "EDpnpS_4v7yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 7.2 Create TinyVGG model class\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG from cnn explainer\n",
        "  \"\"\"\n",
        "  def __init__(self,\n",
        "               input_shape: int,\n",
        "               hidden_units: int,\n",
        "               output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2)\n",
        "    )\n",
        "    self.classifier_layer = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*13*13,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    x = self.conv_block_1(x)\n",
        "    #print(x.shape)\n",
        "    x = self.conv_block_2(x)\n",
        "    #print(x.shape)\n",
        "    x = self.classifier_layer(x)\n",
        "    #print(x.shape)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "PM8_U2HIv8fT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3,\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(class_names)).to(DEVICE_DESTINATION)\n",
        "model_0"
      ],
      "metadata": {
        "id": "g_1vFsDBAtrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 7.3 Try a forward pass on a single image (to test the model)\n",
        "image_batch, label_batch = next(iter(train_dataloader_simple))\n",
        "image_batch.shape"
      ],
      "metadata": {
        "id": "Gik1NrcFBCJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a forward pass\n",
        "model_0(image_batch.to(DEVICE_DESTINATION))"
      ],
      "metadata": {
        "id": "L22eNiu8BCbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 7.4 Use `torch.info` to get an idea of the shapes going through our model"
      ],
      "metadata": {
        "id": "mVEqodujBw2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install torchinfo, import if it's available\n",
        "try:\n",
        "  import torchinfo\n",
        "except:\n",
        "  !pip install torchinfo\n",
        "  import torchinfo\n",
        "\n",
        "from torchinfo import summary\n",
        "summary(model_0, input_size=[1, 3, 64, 64])"
      ],
      "metadata": {
        "id": "QQYBzb1qEniR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 Create train and test loop functions\n",
        "\n",
        "* `train_step()` - takes in a model and dataloader and trains the model on the dataloader\n",
        "* `test_step()` - takes in a model and dataloader and evaluates the model on the dataloader"
      ],
      "metadata": {
        "id": "enqEHxBfE3Eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train_step()\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim,\n",
        "               device: torch.device):\n",
        "  # Put the model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Setup train loss and train accuracy values\n",
        "  acc, loss = 0, 0\n",
        "\n",
        "  # Loop through data loader data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Send data to the target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate the loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    loss += loss.item()\n",
        "\n",
        "    # 3. Optimzier zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate accuracy\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  loss /= len(dataloader)\n",
        "  acc /= len(dataloader)\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "udaPYsJUPRRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a test step\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device):\n",
        "  # Put model in eval mode\n",
        "  model.eval()\n",
        "\n",
        "  # Setup test loss and test accuracy values\n",
        "  loss, acc = 0, 0\n",
        "\n",
        "  # Turn on inference mode\n",
        "  with torch.inference_mode():\n",
        "    # Loop through dataloader batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send data to device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      # 1. Forward pass\n",
        "      test_pred_logits = model(X)\n",
        "\n",
        "      # 2. Calculate the loss\n",
        "      loss += loss_fn(test_pred_logits, y).item()\n",
        "\n",
        "      # 3. Calculate the accuracy\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics to get average loss\n",
        "  loss /= len(dataloader)\n",
        "  acc /= len(dataloader)\n",
        "  return loss, acc"
      ],
      "metadata": {
        "id": "2G4GnmHwROrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.6 Creating `train()` function to combine `train_step()` and `test_step()`\n"
      ],
      "metadata": {
        "id": "QaRuIS2IRw2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Create a train function that takes in various model parameters + optimizer + dataloader + etc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5,\n",
        "          device: torch.device = DEVICE_DESTINATION):\n",
        "  # 2. Create empty results dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []}\n",
        "  # 3. Loop through training and testing steps for a number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer,\n",
        "                                       device=device)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    device=device)\n",
        "    # 4. Print out what's happening\n",
        "    print(f\"Epoch: {epoch} train_loss: {train_loss:.2f} train_acc: {train_acc:.2f} | test_loss: {test_loss:.2f} test_acc: {test_acc:.2f}\")\n",
        "\n",
        "    # 5. Update results dictionary\n",
        "    results['train_loss'].append(train_loss)\n",
        "    results['train_acc'].append(train_acc)\n",
        "    results['test_loss'].append(test_loss)\n",
        "    results['test_acc'].append(test_acc)\n",
        "\n",
        "  # Return the filled results at the end of the epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "zcVXKkxLaTjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7.7 Train and evaluate model 0\n"
      ],
      "metadata": {
        "id": "QgJx4vincFS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set number of epochs\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3,\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(train_data_simple.classes)).to(DEVICE_DESTINATION)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "# Start the timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=DEVICE_DESTINATION)\n",
        "\n",
        "# End the timer and print out how long it took\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time-start_time:.2f}\")"
      ],
      "metadata": {
        "id": "4RSquEivc_j9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PaoV3uRbegX1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}