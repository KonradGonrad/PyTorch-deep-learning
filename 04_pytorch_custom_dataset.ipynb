{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOcOsULuOJDRiyVXPyQdXyT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KonradGonrad/PyTorch-deep-learning/blob/main/04_pytorch_custom_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04. PyTorch Custom Datasets"
      ],
      "metadata": {
        "id": "D1I-4kerC9Zj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Importing PyTorch and setting up device-agnostic code"
      ],
      "metadata": {
        "id": "u-7OAiumDSY8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dmroY6yZ0oVN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# PyTorch 1.10 +\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device-agnostic code\n",
        "DEVICE_DESTINATION = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "DEVICE_DESTINATION"
      ],
      "metadata": {
        "id": "pfjq-9K_DqZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get data"
      ],
      "metadata": {
        "id": "SgNbhPL3EBw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "images_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it\n",
        "if images_path.is_dir():\n",
        "  print(f\"{images_path} already exist. Skipping download...\")\n",
        "else:\n",
        "  print(f\"Creating {images_path} path\")\n",
        "  images_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak and sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", 'wb') as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", 'r') as ziprep:\n",
        "  print(\"Extracking pizza_steak_sushi data...\")\n",
        "  ziprep.extractall(images_path)\n"
      ],
      "metadata": {
        "id": "aCsG-XGzEJyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Becoming one with the data (Data preparation and data exploration)\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"there are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "id": "VMTUdXa486yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir(images_path)"
      ],
      "metadata": {
        "id": "ej5XXmkqKaJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup training and testing part\n",
        "train_dir = images_path / \"train\"\n",
        "test_dir = images_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "jcId2mO_KdKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Visualizing an image\n",
        "\n",
        "1. Get all of the image paths\n",
        "2. Pick a random image path using python's random.choice()\n",
        "3. Get the image class name 'pathlib.Path.parent.stem'\n",
        "4. Since we're working with images, let's open the image with Python's PIL\n",
        "5. We'll then show the image and print metadata"
      ],
      "metadata": {
        "id": "UFD8bcNXK5TJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "# Set seed\n",
        "#random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. Open image with Python PIL\n",
        "img = Image.open(random_image)\n",
        "\n",
        "# 5. Print metadata\n",
        "print(f\"Random image path: {random_image}\")\n",
        "print(f\"Random image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "5OSCOsZgRnU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize image with matplotlib - mine approach\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Set seed\n",
        "#random.seed(42)\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. from random_path into 3 dimension (rgb) image\n",
        "image = mpimg.imread(random_image)\n",
        "\n",
        "# Visualize image with matplotlib\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.axis(False)\n",
        "plt.title(image_class)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VulKJzGtSpzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize image with matplotlib - video approach\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Get all image paths\n",
        "image_paths = list(images_path.glob('*/*/*.jpg'))\n",
        "\n",
        "# 2. Pick a random image path\n",
        "random_image = random.choice(image_paths)\n",
        "\n",
        "# 3. Get the image class name\n",
        "image_class = random_image.parent.stem\n",
        "\n",
        "# 4. Open image with Python PIL\n",
        "img = Image.open(random_image)\n",
        "\n",
        "# 5. Turn the image into an array\n",
        "img_as_array = np.asarray(img)\n",
        "\n",
        "# 6. Plot the image\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.imshow(img_as_array)\n",
        "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color channels] (HWC)\")\n",
        "plt.axis(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ONJC07AgYEA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Transforming data\n",
        "\n",
        "Before we can use our image data with PyTorch:\n",
        "1. Turn your target data into tensors (in our case, numerical representation of our images)\n",
        "2. Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'l call these `Dataset` and `Dataloader`"
      ],
      "metadata": {
        "id": "iPoTSkJ-p0EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "ZBKuyVP630nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Transforming data with `torchvision.transforms`"
      ],
      "metadata": {
        "id": "V1c9Wtwq37C8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our images to 64x64\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p = 0.5),\n",
        "    # Turn the image into a torch tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "rcceh8Lh3-WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform(img).shape"
      ],
      "metadata": {
        "id": "4kGXJ93D5lt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_transformed_images(image_paths: list, transform, n=3, seed=None):\n",
        "  \"\"\"\n",
        "  Selects random images from a path of images and loads/transforms them\n",
        "  then plots the original vs transformed version\n",
        "  \"\"\"\n",
        "  if seed:\n",
        "    random.seed(42)\n",
        "  random_image_paths = random.sample(image_paths, k=n)\n",
        "  for random_image in random_image_paths:\n",
        "    with Image.open(random_image) as f:\n",
        "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[0].axis(False)\n",
        "      ax[0].set_title(f\"Original size: {f.size}\")\n",
        "\n",
        "      transformed_f = transform(f).permute(1, 2, 0)\n",
        "      ax[1].imshow(transformed_f)\n",
        "      ax[1].axis(\"off\")\n",
        "      ax[1].set_title(f\"Shape: {transformed_f.shape}\")\n",
        "\n",
        "      fig.suptitle(f\"Class: {random_image.parent.stem}\", fontsize=16)\n",
        "plot_transformed_images(image_paths,\n",
        "                        data_transform,\n",
        "                        n=3,\n",
        "                        seed=42)\n",
        "\n"
      ],
      "metadata": {
        "id": "1gAFUxkd5qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Option 1: Loading image data using ImageFolder\n",
        "We can load image classification data using `torchvision.datasets.ImageFolder`"
      ],
      "metadata": {
        "id": "bOJX6N70JA85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use ImageFolder to create dataset's\n",
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root=train_dir,\n",
        "                                  transform=data_transform,\n",
        "                                  target_transform=None)\n",
        "\n",
        "test_data = datasets.ImageFolder(root=test_dir,\n",
        "                                 transform=data_transform,\n",
        "                                 target_transform=None)\n",
        "\n",
        "print(train_data, test_data)"
      ],
      "metadata": {
        "id": "WAmSNJJUXK92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names\n",
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "6WixAdYMX1C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get class names as dict\n",
        "class_dict = train_data.class_to_idx\n",
        "class_dict"
      ],
      "metadata": {
        "id": "10Zv_CsAiW8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths of our dataset\n",
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "id": "cLyXaI_f9oZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.samples[0]"
      ],
      "metadata": {
        "id": "SYbTOX_A9yl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index on the train_data Dataset to get a single image and label\n",
        "import random\n",
        "\n",
        "random_idx = random.randint(0, len(train_data))\n",
        "img, label = train_data[random_idx][0], train_data[random_idx][1]\n",
        "print(f\"Image tensor:\\n {img}\")\n",
        "print(f\"Image shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"Image label: {label}\")\n",
        "print(f\"Label datatype: {type(label)}\")"
      ],
      "metadata": {
        "id": "Pk_9CIrN92tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "0KGyah0f-XOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Label: {label} which one is {class_names[label]}\")"
      ],
      "metadata": {
        "id": "66jVCgk7-j3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "print(f\"old shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"new shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y7I7njFw-kYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Turn loaded images into `DataLoaders's`\n",
        "\n",
        "A `Dataloader` is going to help us turn our `Dataset`'s into iterables and we can see `batch_size` images at a time"
      ],
      "metadata": {
        "id": "FmW3wqlmBCtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=os.cpu_count(),\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "nI9sl87U_TlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ],
      "metadata": {
        "id": "YoBSX3oqA5x-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "print(f\"image shape: {img.shape} -> [batch_size, color_channles, height, width]\")\n",
        "print(f\"label shape: {label.shape}\")"
      ],
      "metadata": {
        "id": "0mtPJQA9F8l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Option 2: Loading Image data with a custom `dataset`\n",
        "\n",
        "1. Want to be able to load images from file\n",
        "2. Want to be able to get class names from the dataset\n",
        "3. Want to be able to get classes as dictionary from the dataset\n",
        "\n",
        "Pros:\n",
        "* Can create a `Dataset` out of almost anything\n",
        "* Non limited to PyTorch pre-built `Dataset` functions\n",
        "\n",
        "Cons:\n",
        "* Even though you could create `Dataset` out of almost anything, it doesn't mean it will work\n",
        "* Using a custom `Dataset` often results in us writing more code, which could be prone to errors or performance issues\n",
        "\n",
        "All custom datasets in PyTorch, often subclass `torch.utils.data.Dataset`"
      ],
      "metadata": {
        "id": "HngBoixTGKoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ],
      "metadata": {
        "id": "jF-LPWqWUsks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ],
      "metadata": {
        "id": "FsRc4qZMVgTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Creating a helper function to get class names\n",
        "\n",
        "We want a function to:\n",
        "1. Get the class names using 'os.scandir()' to traverse a taget directory (ideally the directory is in standart image classification format).\n",
        "2. Raise and error if the class names aren't found (ig this happens, there might be something wrong with the directory structure)\n",
        "3. Turn the class names into a dict and a list and return them"
      ],
      "metadata": {
        "id": "AF6Q4gH0Vmrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup path for target directory\n",
        "target_directory = train_dir\n",
        "print(f\"Target dir: {target_directory}\")\n",
        "\n",
        "# Get the class names from the target directory\n",
        "class_names_found = sorted([entry.name for entry in list(os.scandir(target_directory))])\n",
        "class_names_found"
      ],
      "metadata": {
        "id": "gU7RdlaMWie8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(os.scandir(target_directory))"
      ],
      "metadata": {
        "id": "-9BEIpIsWqWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "  \"\"\"\n",
        "  Finds the class folder names in a target directory.\n",
        "  \"\"\"\n",
        "  # 1. Get the class names by scanning the target directory\n",
        "  classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "\n",
        "  # 2. Raise an error if class names could not be found\n",
        "  if not classes:\n",
        "    raise FileNotFoundError(f\"Couldn't find any classes in {directory}...\")\n",
        "\n",
        "  # 3. Create a dictionary of index labels (computers prefer numbers rather than string as labels)\n",
        "  class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "\n",
        "  return classes, class_to_idx"
      ],
      "metadata": {
        "id": "mESOw5hOXILj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_classes(target_directory)"
      ],
      "metadata": {
        "id": "1iNBekQjX306"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = ['Konrad', 'Kamil', 'Wojtek']\n",
        "list((name, i) for i, name in enumerate(x))"
      ],
      "metadata": {
        "id": "e5fD2TxDYGiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MupGgSoWY5oR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}